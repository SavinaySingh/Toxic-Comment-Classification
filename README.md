# Toxic Comment Classification

This repository contains a Jupyter Notebook file (toxic-comment-classification-v01.ipynb) that involves analyzing text comments to determine whether they contain toxic or offensive language. The goal of this task is to develop a model that can accurately identify and flag such comments, with the aim of reducing the prevalence of online harassment, hate speech, and other forms of toxic behavior. 


## Dependencies
- Python 3.8.2

## Installation

## Usage

## Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

# Group Members
- Savinay Singh
- Divgun Singh
- Sagar Sudhir Bhagwatkar
- Somayeh Amraee
